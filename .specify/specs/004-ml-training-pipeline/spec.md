# NFR-010: ML Training Pipeline

> **Status:** Draft  
> **Created:** 2026-02-02  
> **Author:** Kevin Garcia  
> **Priority:** Medium  
> **Type:** Non-Functional Requirement

---

## ğŸ“‹ Overview

Automatisierte Machine Learning Pipeline fÃ¼r kontinuierliches Model-Training, Hyperparameter-Optimierung, Versioning und Deployment. Ziel ist langfristige ModellqualitÃ¤t ohne manuelle Intervention.

---

## ğŸ¯ User Stories

### NFR-10.1: Automatisches Model-Retraining
**Als** System  
**mÃ¶chte ich** das ML-Model regelmÃ¤ssig neu trainieren  
**damit** es mit aktuellen Marktdaten arbeitet

**Akzeptanzkriterien:**
- [ ] Scheduled Retraining (wÃ¶chentlich oder monatlich)
- [ ] Training nur wenn genug neue Daten vorhanden
- [ ] Training-Job lÃ¤uft im Hintergrund (nicht blocking)
- [ ] Notification bei Training-Completion

---

### NFR-10.2: Model Versioning
**Als** Entwickler  
**mÃ¶chte ich** alle Model-Versionen tracken  
**damit** ich bei Problemen rollback machen kann

**Akzeptanzkriterien:**
- [ ] Jedes Model hat eindeutige Version (v1.0.0, v1.1.0, ...)
- [ ] Metrics pro Version gespeichert (accuracy, f1, etc.)
- [ ] Rollback zu vorheriger Version mÃ¶glich
- [ ] Model-Artefakte in MLflow oder S3 gespeichert

---

### NFR-10.3: A/B Testing fÃ¼r Models
**Als** Data Scientist  
**mÃ¶chte ich** neue Models gegen Production testen  
**damit** ich sicher bin dass neue Version besser ist

**Akzeptanzkriterien:**
- [ ] Shadow Mode: Neues Model lÃ¤uft parallel
- [ ] Metrics-Vergleich automatisch
- [ ] Promotion nur wenn neues Model besser
- [ ] Automatische Alerts bei Performance-Drop

---

### NFR-10.4: Drift Detection
**Als** System  
**mÃ¶chte ich** erkennen wenn sich Daten-Distribution Ã¤ndert  
**damit** ich Retraining triggern kann

**Akzeptanzkriterien:**
- [ ] Feature Drift Detection (PSI, KS-Test)
- [ ] Prediction Drift Detection
- [ ] Alert bei signifikantem Drift
- [ ] Optional: Auto-Retrigger Training

---

### NFR-10.5: Hyperparameter-Optimierung
**Als** System  
**mÃ¶chte ich** automatisch beste Hyperparameter finden  
**damit** Model-QualitÃ¤t maximiert wird

**Akzeptanzkriterien:**
- [ ] Optuna oder Ray Tune Integration
- [ ] Bayesian Optimization (nicht Grid Search)
- [ ] Zeit/Resource-Limits definiert
- [ ] Best params in `best_hyperparameters.json` gespeichert

---

## ğŸ—ï¸ Technical Architecture

### Pipeline Stages:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Fetch  â”‚ â†’ â”‚  Feature    â”‚ â†’ â”‚  Training   â”‚ â†’ â”‚ Evaluation  â”‚
â”‚ (yfinance)  â”‚   â”‚ Engineering â”‚   â”‚ (XGBoost)   â”‚   â”‚ (Backtest)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  MLflow     â”‚
                                    â”‚ (Versioning)â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  Promotion  â”‚
                                    â”‚ (if better) â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tools:
| Component | Tool | Status |
|-----------|------|--------|
| Versioning | MLflow | âœ… Exists |
| Scheduling | GitHub Actions / Cron | ğŸ”§ To Setup |
| Hyperparameter | Optuna | ğŸ”§ To Add |
| Drift Detection | Evidently AI | ğŸ”§ To Add |
| Storage | Local / S3 | âœ… Exists |

### Existing Assets:
- `src/training/` - Training scripts
- `mlruns/` - MLflow experiment tracking
- `best_hyperparameters.json` - Current best params
- `models/` - Saved model files

---

## ğŸ“… Implementation Phases

### Phase 1: Manual Pipeline (Current)
- Training scripts exist
- MLflow tracking works
- Manual execution required

### Phase 2: Scheduled Training
- GitHub Actions workflow for weekly training
- Auto-commit new model if better
- Slack/Email notification

### Phase 3: Full Automation
- Drift detection triggers retraining
- A/B testing for model promotion
- Auto-rollback on performance drop

---

## âš ï¸ Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Neues Model schlechter | Predictions verschlechtern sich | A/B Testing, Rollback |
| Training zu teuer (Zeit) | Blocking andere Prozesse | Background Jobs, Limits |
| Overfitting auf neue Daten | Model generalisiert nicht | Cross-Validation, Holdout |
| Drift false positives | UnnÃ¶tiges Retraining | Thresholds tunen |

---

## ğŸ“Š Success Metrics

| Metrik | Zielwert |
|--------|----------|
| Training Duration | < 30 Minuten |
| Model Accuracy | > 65% |
| Drift Detection Latency | < 24h |
| Rollback Time | < 5 Minuten |
| Retraining Frequency | 1x pro Monat (min) |

---

## ğŸ”— Dependencies

- MLflow (bereits installiert)
- Optuna (zu installieren)
- GitHub Actions (bereits vorhanden)
- Sufficient training data (6+ months)

---

## ğŸ“ Notes

- PrioritÃ¤t: NFR-10.1 (Scheduled Training) zuerst
- A/B Testing und Drift Detection sind "nice-to-have"
- Existierende `src/training/` Scripts wiederverwenden
- Nicht zu frÃ¼h optimieren - einfach starten, dann iterieren
