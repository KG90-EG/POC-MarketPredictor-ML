# FR-003: LLM-Powered Market Analysis

> **Status:** ‚úÖ Completed  
> **Created:** 2026-02-02  
> **Completed:** 2026-02-03  
> **Author:** Kevin Garcia  
> **Priority:** Medium  
> **Type:** Functional Requirement

---

## üìã Overview

Integration von Large Language Models (LLM) f√ºr intelligente Marktanalyse, Sentiment-Erkennung und nat√ºrlichsprachliche Erkl√§rungen von Trading-Signalen.

---

## üéØ User Stories

### FR-3.1: AI-Erkl√§rungen f√ºr Trading-Signale ‚úÖ
**Als** Trader  
**m√∂chte ich** verstehen WARUM die AI BUY/SELL empfiehlt  
**damit** ich fundierte Entscheidungen treffen kann

**Akzeptanzkriterien:**
- [x] Jedes Signal hat eine menschenlesbare Erkl√§rung
- [x] Erkl√§rung nennt 3-5 Hauptfaktoren
- [x] Erkl√§rung ist in 2-3 S√§tzen zusammengefasst
- [x] Keine halluzinierten Fakten (LLM-Guardrails)

**Beispiel:**
```
BUY AAPL (85% Confidence)
"Apple zeigt starkes Momentum nach den Quartalszahlen. 
RSI bei 45 deutet auf Aufw√§rtspotenzial. 
Volumen 20% √ºber Durchschnitt signalisiert Kaufinteresse."
```

---

### FR-3.2: News Sentiment-Analyse ‚è≥
**Als** Trader  
**m√∂chte ich** die Marktstimmung zu einem Asset sehen  
**damit** ich News-getriebene Bewegungen verstehe

**Akzeptanzkriterien:**
- [x] Sentiment-Score: Bullish / Neutral / Bearish
- [ ] Top 3 relevante News-Headlines anzeigen (deferred)
- [ ] Sentiment aktualisiert sich mindestens t√§glich (deferred)
- [ ] Quellen werden angegeben (deferred)

**Note:** Basic sentiment based on technical analysis implemented. Full news integration planned for future.

---

### FR-3.3: Marktregime-Erkl√§rung ‚úÖ
**Als** Trader  
**m√∂chte ich** verstehen warum wir in RISK_ON/RISK_OFF sind  
**damit** ich meine Strategie anpassen kann

**Akzeptanzkriterien:**
- [x] LLM erkl√§rt aktuelles Marktregime
- [x] Nennt makro√∂konomische Faktoren
- [ ] Vergleicht mit historischen Situationen (optional - deferred)

---

### FR-3.4: Chat-Interface (Optional/Future) ‚è≥
**Als** Trader  
**m√∂chte ich** Fragen zur Marktlage stellen k√∂nnen  
**damit** ich schnell Antworten bekomme

**Akzeptanzkriterien:**
- [ ] Einfaches Chat-Input-Feld
- [ ] Antworten basieren auf aktuellen Daten
- [ ] Kontext-aware (kennt aktuelle Positionen)

---

## üèóÔ∏è Technical Approach

### LLM Provider Options:
| Provider | Pros | Cons |
|----------|------|------|
| **Claude API** | Beste Qualit√§t, lange Kontexte | Kosten, Latenz |
| **OpenAI GPT-4** | Schnell, gut f√ºr Summaries | Kosten |
| **Local Ollama** | Kostenlos, privat | Qualit√§t, Hardware |
| **Groq (Llama)** | Sehr schnell, g√ºnstig | Qualit√§t variabel |

### Empfehlung:
- **Phase 1:** Groq/Llama f√ºr schnelle, g√ºnstige Erkl√§rungen
- **Phase 2:** Claude API f√ºr komplexe Analysen (optional)

### API Design:
```
GET /api/explain/{ticker}
‚Üí { "explanation": "...", "factors": [...], "sentiment": "bullish" }

GET /api/sentiment/{ticker}
‚Üí { "score": 0.75, "label": "bullish", "headlines": [...] }

GET /api/regime/explain
‚Üí { "regime": "RISK_ON", "explanation": "...", "factors": [...] }
```

---

## ‚ö†Ô∏è Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| LLM Halluzinationen | User bekommt falsche Infos | Guardrails, Faktencheck |
| API-Kosten explodieren | Budget-√úberschreitung | Rate Limits, Caching |
| Latenz zu hoch | Schlechte UX | Background-Processing, Cache |
| LLM-Ausfall | Feature nicht verf√ºgbar | Graceful Degradation |

---

## üìä Success Metrics

| Metrik | Zielwert |
|--------|----------|
| Explanation Latency | < 3 Sekunden |
| User Engagement | +20% Time on Page |
| Accuracy (no hallucinations) | > 95% |
| API Cost per User/Day | < $0.05 |

---

## üîó Dependencies

- LLM Provider API Key
- News Data Source (Yahoo Finance, Alpha Vantage)
- Existing `/predict` and `/regime` endpoints

---

## üìù Notes

- Start mit einfachen Template-basierten Erkl√§rungen als Fallback
- LLM nur f√ºr "Premium" Erkl√§rungen, nicht f√ºr jede Prediction
- Caching aggressive nutzen (gleiche Frage = gleiche Antwort f√ºr 1h)
