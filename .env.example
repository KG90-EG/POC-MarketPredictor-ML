# POC-MarketPredictor-ML Environment Variables
# Copy this file to .env and configure as needed

# ============================================
# REQUIRED - Model Configuration
# ============================================

# Path to the production model file
PROD_MODEL_PATH=models/prod_model.bin

# ============================================
# OPTIONAL - Caching
# ============================================

# Enable Redis caching (default: false - uses in-memory cache)
# Set to 'true' to enable Redis
USE_REDIS=false

# Redis connection URL (only needed if USE_REDIS=true)
# REDIS_URL=redis://localhost:6379/0

# ============================================
# OPTIONAL - Rate Limiting
# ============================================

# Maximum requests per minute per IP (default: 60)
RATE_LIMIT_RPM=60

# ============================================
# OPTIONAL - OpenAI Integration
# ============================================

# OpenAI API key for AI-powered stock analysis
# Get your key at: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-api-key-here

# ============================================
# OPTIONAL - LLM Analysis (FR-003)
# ============================================

# LLM provider: groq (default), openai, anthropic
LLM_PROVIDER=groq

# Groq API key (default provider - fast & affordable)
# Get your key at: https://console.groq.com/keys
# GROQ_API_KEY=gsk_your-api-key-here

# Anthropic API key (alternative provider)
# Get your key at: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-your-api-key-here

# Cache TTL for LLM responses in seconds (default: 3600 = 1 hour)
LLM_CACHE_TTL=3600

# ============================================
# OPTIONAL - ML Experiment Tracking
# ============================================

# MLflow tracking server URI
# Leave empty to use local file-based tracking
# MLFLOW_TRACKING_URI=http://localhost:5000

# ============================================
# OPTIONAL - AWS S3 Model Storage
# ============================================

# AWS credentials for model storage/retrieval
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key
# S3_BUCKET=your-bucket-name

# ============================================
# OPTIONAL - Logging
# ============================================

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# ============================================
# OPTIONAL - Server Configuration
# ============================================

# Server host and port (for production)
# HOST=0.0.0.0
# PORT=8000

# Number of worker processes (for gunicorn)
# WORKERS=4

# ============================================
# DEVELOPMENT SETTINGS
# ============================================

# Set to 'development' for development mode
# ENVIRONMENT=production

# Enable debug mode (not recommended for production)
# DEBUG=false

# ============================================
# NOTES
# ============================================
#
# 1. Never commit .env file to git (it's in .gitignore)
# 2. For production, set these as environment variables in your deployment platform
# 3. For local development, copy this to .env and uncomment needed variables
# 4. All settings have sensible defaults and will work without configuration
#
# Quick Start (minimal setup):
# - Copy: cp .env.example .env
# - No changes needed! Everything works with defaults
#
# Production Setup (all features):
# - Set OPENAI_API_KEY for AI analysis
# - Set USE_REDIS=true and REDIS_URL for distributed caching
# - Set AWS credentials for S3 model storage
# - Set MLFLOW_TRACKING_URI for centralized experiment tracking
